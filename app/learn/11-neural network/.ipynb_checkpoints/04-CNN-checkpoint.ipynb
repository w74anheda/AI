{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6c8179",
   "metadata": {},
   "source": [
    "#  Convolutional Neural Network (CNN, or ConvNet)\n",
    "\n",
    "### Convolutional:\n",
    "<img src='../../img/1_CnNorCR4Zdq7pVchdsRGyw.png'>\n",
    "<img src='../../img/giadascxvfdgephy.gif'>\n",
    "\n",
    "### add padding:\n",
    "<img src='../../img/1 nYf_cUIHFEWU1JXGwnz-Ig.gif'>\n",
    "\n",
    "### polling:\n",
    "<img src='../../img/maxpool_animation.gif'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaace6ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 22:31:23.721485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-06 22:31:23.721526: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-06 22:31:24.687491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 22:31:24.687629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 22:31:24.687643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet import ResNet152, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "import matplotlib.pyplot as PLT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a6bcc",
   "metadata": {},
   "source": [
    "# Popular CNN Model\n",
    "\n",
    "### search : cnn best architecture\n",
    "\n",
    "* lenet 5\n",
    "* alexnet\n",
    "* zfnet\n",
    "* vgg\n",
    "* googlenet (inception) - inception v3\n",
    "* resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet152(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca13718",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f29efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('../../img/dog2.webp',target_size=(224,224))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86dd48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image.img_to_array(img)\n",
    "print(X.shape)\n",
    "X = np.expand_dims(X,axis=0)\n",
    "print(X.shape)\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e798439",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict(X)\n",
    "Y_predict = decode_predictions(Y_predict, top=10)\n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727243b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435336a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.resize(frame,(224,224))\n",
    "    image = frame[...,::-1] #bgr to rgb\n",
    "    X = np.expand_dims(image,axis=0)\n",
    "    X = preprocess_input(X)\n",
    "    Y_predict = model.predict(X)\n",
    "    name = decode_predictions(Y_predict, top=1)[0][0][1]\n",
    "    cv2.putText(frame, name, (30,30), cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,0))\n",
    "    cv2.imshow('webcam', frame)\n",
    "#     cv2.cvtColor(cv2.COLOR_BGR2RGB)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96449a73",
   "metadata": {},
   "source": [
    "# CNN Movie Polarity Detection\n",
    "\n",
    "### dataset url : https://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "## search  : keras text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f377ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model,Sequential,load_model\n",
    "from tensorflow.keras.layers import Input,Dense,Flatten,Embedding,Conv1D,MaxPool1D,concatenate,Dropout,Conv2D,MaxPool2D,Activation,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589770e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def punctuation_cleaner(string):\n",
    "    global punctuation\n",
    "    punctuation = punctuation+'\\n\\\\//'\n",
    "    s = str.maketrans('','',punctuation)\n",
    "    return string.translate(s)\n",
    "\n",
    "stopwords_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ed987",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_document = []\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for file_name in os.listdir('../../../datasets/PolarityDetection/neg/'):\n",
    "    with open(f'../../../datasets/PolarityDetection/neg/{file_name}') as f:\n",
    "        text = f.read()\n",
    "        text = punctuation_cleaner(text)\n",
    "        text = word_tokenize(text)\n",
    "        text = [w for w in text if w not in stopwords_en]\n",
    "        text = set([stemmer.stem(w) for w in text])\n",
    "        negative_document.append([' '.join(text),0])\n",
    "        \n",
    "positive_document = []\n",
    "for file_name in os.listdir('../../../datasets/PolarityDetection/pos/'):\n",
    "    with open(f'../../../datasets/PolarityDetection/pos/{file_name}') as f:\n",
    "        text = f.read()\n",
    "        text = punctuation_cleaner(text)\n",
    "        text = word_tokenize(text)\n",
    "        text = [w for w in text if w not in stopwords_en]\n",
    "        text = [stemmer.stem(w) for w in text]\n",
    "        text = [lemmatizer.lemmatize(w) for w in text]\n",
    "        positive_document.append([' '.join(text),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd19b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF = pd.DataFrame(positive_document,columns=['text','target'])\n",
    "NDF = pd.DataFrame(negative_document,columns=['text','target'])\n",
    "DF = pd.concat([PDF,NDF],axis=0)\n",
    "DF = DF.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff759aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = DF['text'].str.split(' ').str.len().max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(DF.iloc[:,:-1],DF['target'],test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(tokenizer.word_index) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910999b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train['text'])\n",
    "X_train = pad_sequences(X_train,maxlen=max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(X_test['text'])\n",
    "X_test = pad_sequences(X_test,maxlen=max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab25dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = Input(shape=(max_len,))\n",
    "# embeding1 = Embedding(max_len,100)(input1)\n",
    "# conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embeding1)\n",
    "# dropout1 = Dropout(.5)(conv1)\n",
    "# maxpool1 = MaxPool1D(pool_size=2)(dropout1)\n",
    "# flat = Flatten()(maxpool1)\n",
    "# dense1 = Dense(10,activation='relu')(flat)\n",
    "# output = Dense(1,activation='sigmoid')(dense1)\n",
    "\n",
    "# model = Model(inputs=[input1],outputs=output)\n",
    "\n",
    "# model.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer = 'adam',\n",
    "#     metrics=['accuracy']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_len,output_dim=200,input_shape=(max_len,)),\n",
    "    Conv1D(filters=32, kernel_size=4, activation='relu'),\n",
    "    Dropout(.2),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(10,activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edb639",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,Y_train,epochs=10,batch_size=100,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fabc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../../../datasets/models/movie_polarity_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55187201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model('../../../datasets/models/movie_polarity_detection.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06029899",
   "metadata": {},
   "source": [
    "## Multi Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f29287",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(max_len,))\n",
    "embeding1 = Embedding(vocab_len,500)(input1)\n",
    "conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embeding1)\n",
    "# dropout1 = Dropout(.5)(conv1)\n",
    "maxpool1 = MaxPool1D(pool_size=2)(conv1)\n",
    "flat1 = Flatten()(maxpool1)\n",
    "\n",
    "input2 = Input(shape=(max_len,))\n",
    "embeding2 = Embedding(vocab_len,500)(input2)\n",
    "conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embeding2)\n",
    "# dropout2 = Dropout(.5)(conv2)\n",
    "maxpool2 = MaxPool1D(pool_size=2)(conv2)\n",
    "flat2 = Flatten()(maxpool2)\n",
    "\n",
    "input3 = Input(shape=(max_len,))\n",
    "embeding3 = Embedding(vocab_len,500)(input3)\n",
    "conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embeding3)\n",
    "# dropout3 = Dropout(.5)(conv3)\n",
    "maxpool3 = MaxPool1D(pool_size=2)(conv3)\n",
    "flat3 = Flatten()(maxpool3)\n",
    "\n",
    "flatX = concatenate([flat1,flat2,flat3])\n",
    "dense1 = Dense(100,activation='relu')(flatX)\n",
    "dense2 = Dense(10,activation='relu')(dense1)\n",
    "output = Dense(1,activation='sigmoid')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input1,input2,input3],outputs=output)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5a2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,show_layer_names=False,show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebca5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [X_train,X_train,X_train],\n",
    "    Y_train,\n",
    "    epochs=20,\n",
    "    batch_size=100,\n",
    "    validation_data=([X_test,X_test,X_test],Y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../../../datasets/models/movie_polarity_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cccdf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLT.plot(history.history['accuracy'], color='green', label='train data')\n",
    "PLT.plot(history.history['val_accuracy'], color='red', label='test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLT.plot(history.history['loss'], color='green', label='train data')\n",
    "PLT.plot(history.history['val_loss'], color='red', label='test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed6eb8",
   "metadata": {},
   "source": [
    "# House Price Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbce65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de91655",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('../../../datasets/Houses Dataset/HousesInfo.txt',header=None,sep=' ',\n",
    "                names=['bedrooms','bathrooms','area','zipcode','price'])\n",
    "DF.index = np.arange(1, len(DF)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e47a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>area</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4053</td>\n",
       "      <td>85255</td>\n",
       "      <td>869500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  area  zipcode   price\n",
       "1         4        4.0  4053    85255  869500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9195998",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in DF.index.values:\n",
    "    basepath = os.path.sep.join([\n",
    "        '../../../datasets/Houses Dataset',\n",
    "        \"{}_*\".format(i)\n",
    "    ])\n",
    "    imgPaths = sorted(glob.glob(basepath))\n",
    "    inputImages = []\n",
    "    for imgPath in imgPaths:\n",
    "        img = cv2.cvtColor(cv2.resize(cv2.imread(imgPath),(128,128)),cv2.COLOR_BGR2RGB)\n",
    "        inputImages.append(img)\n",
    "    outputImages = np.zeros((256,256,3),dtype=np.int32)\n",
    "    outputImages[0:128,0:128] = inputImages[0]\n",
    "    outputImages[0:128,128:256] = inputImages[1]\n",
    "    outputImages[128:256,128:256] = inputImages[2]\n",
    "    outputImages[128:256,0:128] = inputImages[3]\n",
    "    images.append(outputImages)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca9eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FlattenIMG = pd.DataFrame(images.reshape(535,-1))\n",
    "FlattenIMG.index = np.arange(1, len(FlattenIMG)+1)\n",
    "NEWDF = pd.concat([DF,FlattenIMG],axis=1)\n",
    "\n",
    "MaxPrice = NEWDF['price'].max()\n",
    "X = NEWDF[NEWDF.columns.difference(['price'])]\n",
    "Y = NEWDF['price'] / MaxPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2085bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>196602</th>\n",
       "      <th>196603</th>\n",
       "      <th>196604</th>\n",
       "      <th>196605</th>\n",
       "      <th>196606</th>\n",
       "      <th>196607</th>\n",
       "      <th>area</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>156</td>\n",
       "      <td>126</td>\n",
       "      <td>185</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>98</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>97</td>\n",
       "      <td>114</td>\n",
       "      <td>175</td>\n",
       "      <td>4053</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 196612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7   8    9  ...  196602  196603  \\\n",
       "1  181  156  126  185  168  128  159  124  98  154  ...     121     134   \n",
       "\n",
       "   196604  196605  196606  196607  area  bathrooms  bedrooms  zipcode  \n",
       "1     134      97     114     175  4053        4.0         4    85255  \n",
       "\n",
       "[1 rows x 196612 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46474ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLECOLs = ['area','bathrooms','bedrooms','zipcode']\n",
    "IMGCOLS = X.columns.difference(TABLECOLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1f366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state=3020,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed9e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 22:32:09.052382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/masoud/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-06 22:32:09.052413: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-06 22:32:09.052446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: masoud-Aspire-V3-571G\n",
      "2022-12-06 22:32:09.052455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: masoud-Aspire-V3-571G\n",
      "2022-12-06 22:32:09.052544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-12-06 22:32:09.052588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.157.0\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(256,256,3))\n",
    "conv1 = Conv2D(16,(3,3),padding='same',activation='relu')(input1)\n",
    "batch_norm_1 = BatchNormalization(axis=-1)(conv1)\n",
    "maxpool1 = MaxPool2D(pool_size=(2,2))(batch_norm_1)\n",
    "conv2 = Conv2D(32,(3,3),padding='same',activation='relu')(input1)\n",
    "batch_norm_2 = BatchNormalization(axis=-1)(conv2)\n",
    "maxpool2 = MaxPool2D(pool_size=(2,2))(batch_norm_2)\n",
    "conv3 = Conv2D(64,(3,3),padding='same',activation='relu')(input1)\n",
    "batch_norm_3 = BatchNormalization(axis=-1)(conv3)\n",
    "maxpool3 = MaxPool2D(pool_size=(2,2))(batch_norm_3)\n",
    "flatten1 = Flatten()(maxpool3)\n",
    "dense1 = Dense(100,activation='relu')(flatten1)\n",
    "batch_norm_4 = BatchNormalization(axis=-1)(dense1)\n",
    "dense2 = Dense(10,activation='relu')(batch_norm_4)\n",
    "model1 = Model(input1,dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa43c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(50,activation='relu',input_dim=4))\n",
    "model2.add(Dense(25,activation='relu'))\n",
    "model2.add(Dense(10,activation='relu'))\n",
    "model2.add(Dense(10,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e07ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_input = concatenate([model1.output,model2.output])\n",
    "dense_final_1 = Dense(10,activation='relu')(combine_input)\n",
    "dense_final_2 = Dense(1,activation='linear')(dense_final_1) # sigmoid\n",
    "modelX = Model(inputs=[model1.input,model2.input], outputs=dense_final_2)\n",
    "modelX.compile(\n",
    "    loss='mean_absolute_error',\n",
    "    optimizer = 'adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6bbd363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 22:33:06.096665: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 838860800 exceeds 10% of free system memory.\n",
      "2022-12-06 22:33:06.672227: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 838860800 exceeds 10% of free system memory.\n",
      "2022-12-06 22:33:10.453768: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 838860800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/9 [==>...........................] - ETA: 1:15 - loss: 9132.2617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 22:33:12.902119: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 838860800 exceeds 10% of free system memory.\n",
      "2022-12-06 22:33:13.460174: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 838860800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 65s 7s/step - loss: 5848.5229 - val_loss: 1818.3927\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 61s 7s/step - loss: 979.1451 - val_loss: 442.6406\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 67s 8s/step - loss: 265.4567 - val_loss: 57.9060\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 69s 8s/step - loss: 2.0152 - val_loss: 33.7585\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 69s 8s/step - loss: 1.5489 - val_loss: 13.3219\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 68s 8s/step - loss: 0.9567 - val_loss: 1.0869\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 69s 8s/step - loss: 0.6010 - val_loss: 0.8628\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 70s 8s/step - loss: 0.4159 - val_loss: 1.5155\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.3118 - val_loss: 0.4870\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 71s 8s/step - loss: 0.2137 - val_loss: 0.6872\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.1548 - val_loss: 0.3099\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 67s 7s/step - loss: 0.1510 - val_loss: 0.2824\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 69s 8s/step - loss: 0.1406 - val_loss: 0.3257\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.1154 - val_loss: 0.5174\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.1118 - val_loss: 0.3241\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0982 - val_loss: 0.2117\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0895 - val_loss: 0.2504\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0888 - val_loss: 0.1891\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0857 - val_loss: 0.1803\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0832 - val_loss: 0.1903\n"
     ]
    }
   ],
   "source": [
    "histrory = modelX.fit(\n",
    "    [\n",
    "        X_train[IMGCOLS].to_numpy().reshape(len(X_train),256,256,3),\n",
    "        X_train[TABLECOLs]\n",
    "    ],Y_train,\n",
    "    validation_data=(\n",
    "        [\n",
    "            X_test[IMGCOLS].to_numpy().reshape(len(X_test),256,256,3),\n",
    "            X_test[TABLECOLs]\n",
    "        ],Y_test\n",
    "    ),\n",
    "    epochs=20,\n",
    "    batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b299266",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(modelX,show_layer_names=False,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c94d1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 742ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_predicted = modelX.predict([\n",
    "    X_test[IMGCOLS].to_numpy().reshape(len(X_test),256,256,3),\n",
    "    X_test[TABLECOLs]\n",
    "]) * MaxPrice\n",
    "Y_predicted = Y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49686ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114574.503006676"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = abs(Y_predicted - ( Y_test.values * MaxPrice ))\n",
    "diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52186330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589362.8112149533"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWDF['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "534b9f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.350000e+02\n",
       "mean     5.893628e+05\n",
       "std      5.090261e+05\n",
       "min      2.200000e+04\n",
       "25%      2.492000e+05\n",
       "50%      5.290000e+05\n",
       "75%      7.285000e+05\n",
       "max      5.858000e+06\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWDF['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ec42bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d98ba13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.75167280848191"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred=Y_predicted,y_true=( Y_test.values * MaxPrice ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "621347e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114574.503006676"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred=Y_predicted,y_true=( Y_test.values * MaxPrice ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1d684",
   "metadata": {},
   "source": [
    "# Simple one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipbin = LabelBinarizer() #simple one hot encode\n",
    "zipbin.fit(NEWDF['zipcode'])\n",
    "zipbin.transform(X_train['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330dedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d012550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa2d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a8746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8bc27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd92a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40266dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa2cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f1df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac74b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3b835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43653b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca32147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eaf76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
