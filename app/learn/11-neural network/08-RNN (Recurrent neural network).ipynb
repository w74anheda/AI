{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b40968",
   "metadata": {},
   "source": [
    "# RNN (Recurrent neural network) : \n",
    "### is good for sequenced (Text, Time Series) problem\n",
    "<img src=\"../../img/RNN-vs-LSTM-vs-GRU-1200x361.png\">\n",
    "<img src=\"../../img/1 d_POV7c8fzHbKuTgJzCxtA.gif\">\n",
    "<img src=\"../../img/rnn_rel.jpeg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaace6ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as PLT\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,SimpleRNN,Dropout,LSTM,GRU,BatchNormalization,Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b93366",
   "metadata": {},
   "source": [
    "# Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0,2000)\n",
    "x = np.sin( .01* t)\n",
    "X_train,X_test= x[:1500],x[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain,YTrain = [],[]\n",
    "XTest,YTest = [],[]\n",
    "seq = 5\n",
    "\n",
    "for start in range(len(X_train)- seq):\n",
    "    end = start + seq\n",
    "    XTrain.append(X_train[start:end,])\n",
    "    YTrain.append(X_train[end])\n",
    "    \n",
    "for start in range(len(X_test)- seq):\n",
    "    end = start + seq\n",
    "    XTest.append(X_test[start:end,])\n",
    "    YTest.append(X_test[end])\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = np.array(XTrain), np.array(XTest), np.array(YTrain), np.array(YTest)\n",
    "X_train = np.reshape( X_train,(X_train.shape[0],X_train.shape[1],1) )\n",
    "X_test = np.reshape( X_test,(X_test.shape[0],X_test.shape[1],1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254ca55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PLT.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,Y_train, epochs=100,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test) # return mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_predicted = model.predict(X_train)\n",
    "X_test_predicted = model.predict(X_test)\n",
    "X_final = np.concatenate([X_train_predicted,X_test_predicted],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLT.plot(x, c='blue')\n",
    "PLT.plot(X_final, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02b66c",
   "metadata": {},
   "source": [
    "# Simple RNN predict Foolad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('../../../datasets/foolad.csv')\n",
    "DF = DF.sort_values(by='<DTYYYYMMDD>').reset_index(drop=True)\n",
    "DF['<DTYYYYMMDD>'] = DF['<DTYYYYMMDD>'].apply(lambda date: ''.join([ f'{v}-' if i in [3,5] else v for (i,v) in enumerate(str(date)) ]))\n",
    "DF['<DTYYYYMMDD>'] = pd.to_datetime(DF['<DTYYYYMMDD>'])\n",
    "DF.rename(columns={\n",
    "    '<DTYYYYMMDD>' : 'Date',\n",
    "    '<FIRST>':'Open',\n",
    "    '<HIGH>':'High',\n",
    "    '<LOW>':'Low',\n",
    "    '<CLOSE>':'Close',\n",
    "    '<VALUE>':'Volume',\n",
    "},inplace=True)\n",
    "DF.set_index('Date',inplace=True)\n",
    "DF = DF[['Open','High','Low','Close','Volume']]\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b787a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLT.figure(figsize=(15,5))\n",
    "PLT.plot(DF['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DF['Close'].values\n",
    "X_train,X_test = data[:2500],data[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd56667",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain,YTrain = [],[]\n",
    "XTest,YTest = [],[]\n",
    "seq = 30\n",
    "\n",
    "for start in range(len(X_train)- seq):\n",
    "    end = start + seq\n",
    "    XTrain.append(X_train[start:end,])\n",
    "    YTrain.append(X_train[end])\n",
    "    \n",
    "for start in range(len(X_test)- seq):\n",
    "    end = start + seq\n",
    "    XTest.append(X_test[start:end,])\n",
    "    YTest.append(X_test[end])\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = np.array(XTrain), np.array(XTest), np.array(YTrain), np.array(YTest)\n",
    "X_train = np.reshape( X_train,(X_train.shape[0],X_train.shape[1],1) )\n",
    "X_test = np.reshape( X_test,(X_test.shape[0],X_test.shape[1],1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=64, activation='relu')) # tanh\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,Y_train, epochs=50,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test) # return mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_predicted = model.predict(X_train)\n",
    "X_test_predicted = model.predict(X_test)\n",
    "X_final = np.concatenate([X_train_predicted,X_test_predicted],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f11be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLT.figure(figsize=(15,5))\n",
    "\n",
    "PLT.plot(data, c='blue')\n",
    "PLT.plot(X_final, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a538a",
   "metadata": {},
   "source": [
    "# Currency Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7726b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from sklearn import preprocessing\n",
    "import datetime as dt\n",
    "import pandas_datareader as web \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581db79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOOLAD = DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655d0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.datetime(2018,1,1)\n",
    "end = dt.datetime.now()\n",
    "DOGE = web.DataReader('DOGE-USD', 'yahoo', start, end)\n",
    "\n",
    "\n",
    "# DOGE = DOGE.reset_index()\n",
    "# DOGE['Date'] = pd.to_datetime(DOGE['Date'])\n",
    "# DOGE = DOGE.rename(columns={'Date':'Date'})\n",
    "# DOGE.drop(columns=['Adj Close'],inplace=True)\n",
    "# DOGE.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ac69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOOLAD.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DOGE.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['future'] = DF['Close'].shift(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a51069",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(future,current):\n",
    "    return 1 if future > current else 0\n",
    "DF['target'] = list(map(compare, DF['future'], DF['Close']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4464e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_currency(DF,COLS,seq):\n",
    "    DF = DF.copy()\n",
    "    for c in COLS:\n",
    "        DF[c] = DF[c].pct_change()\n",
    "        DF.dropna(inplace=True)\n",
    "        DF[c] = preprocessing.scale(DF[c])\n",
    "    DF.dropna(inplace=True)\n",
    "    sequences = []\n",
    "    prev_days = deque(maxlen=seq)\n",
    "    for i in DF.values:\n",
    "        prev_days.append(i[:-2])\n",
    "        if len(prev_days) == seq:\n",
    "            sequences.append([np.array(prev_days),i[-1]])\n",
    "#     print(sequences)        \n",
    "    random.shuffle(sequences)\n",
    "    buys = []\n",
    "    sells= []\n",
    "    for sequence, target in sequences:\n",
    "        if target == 0:\n",
    "            sells.append([sequence,target])\n",
    "        else :\n",
    "            buys.append([sequence,target])\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower = min(len(buys), len(sells))\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "    sequences = buys+sells\n",
    "    random.shuffle(sequences)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for seq, target in sequences:\n",
    "        X.append(seq)\n",
    "        Y.append(target)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff992605",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train, DF_test = train_test_split(DF,test_size=.4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 90\n",
    "X_COLS = DF.columns.difference(['future','target'])\n",
    "                               \n",
    "X_train, Y_train = preprocess_currency(DF_train,X_COLS,seq)\n",
    "X_test, Y_test = preprocess_currency(DF_test,X_COLS,seq)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( \n",
    "    LSTM(units=32,\n",
    "         input_shape=(X_train.shape[1:]),\n",
    "         activation='relu',\n",
    "#          return_sequences=True\n",
    "        ) \n",
    ") \n",
    "# model.add(BatchNormalization())\n",
    "# model.add(GRU(units=12,activation='relu',)) \n",
    "model.add(Dense(10))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(10))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fa7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,Y_train, epochs=100,batch_size=50, validation_data=(X_test,Y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = model.predict(X_test)\n",
    "Y_predicted = [np.argmax(x) for x in Y_predicted]\n",
    "# Y_predicted = [1 if x[1]>.4 else 0 for x in Y_predicted]\n",
    "\n",
    "print(metrics.classification_report(Y_test,Y_predicted))\n",
    "print(metrics.confusion_matrix(Y_test,Y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b005537",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = DF.iloc[len(DF)-15:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee033e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.argmax(model.predict(\n",
    " [today.values]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb84c3",
   "metadata": {},
   "source": [
    "# LSTM Currency Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8c3c7d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>6259550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>4246520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>2231080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>3288960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>2481270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close   Volume\n",
       "Date                                                                  \n",
       "2017-11-09  0.001207  0.001415  0.001181  0.001415   0.001415  6259550\n",
       "2017-11-10  0.001421  0.001431  0.001125  0.001163   0.001163  4246520\n",
       "2017-11-11  0.001146  0.001257  0.001141  0.001201   0.001201  2231080\n",
       "2017-11-12  0.001189  0.001210  0.001002  0.001038   0.001038  3288960\n",
       "2017-11-13  0.001046  0.001212  0.001019  0.001211   0.001211  2481270"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv('../../../datasets/DOGE-USD(6).csv')\n",
    "DF['Date'] = pd.to_datetime(DF['Date'])\n",
    "DF.set_index('Date',inplace=True)\n",
    "DF.dropna(inplace=True)\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1b3cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train, DF_test = train_test_split(DF,test_size=.3,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f916f6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d38fd4a30>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PLT.figure(figsize=(15,5))\n",
    "PLT.plot(DF_train['Close'], c='blue',label='train_data')\n",
    "PLT.plot(DF_test['Close'], c='orange',label='test_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b03d938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_window_data(DF,window):\n",
    "    window_data = []\n",
    "    for i in range(len(DF)- window):\n",
    "        tmp = DF[i:(i+window)].copy()\n",
    "        window_data.append(tmp.values)\n",
    "    return np.array(window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3f590d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(DF,TARGET_COL,window):\n",
    "    DF_train, DF_test = train_test_split(DF,test_size=.1,shuffle=False)\n",
    "    \n",
    "    X_train = extract_window_data(\n",
    "        DF_train[DF_train.columns.difference([TARGET_COL])],\n",
    "        window\n",
    "    )\n",
    "    \n",
    "    X_test = extract_window_data(\n",
    "        DF_test[DF_test.columns.difference([TARGET_COL])],\n",
    "        window\n",
    "    )\n",
    "    \n",
    "    Y_train = DF_train[TARGET_COL][window:].values\n",
    "    Y_test = DF_test[TARGET_COL][window:].values\n",
    "    \n",
    "    Y_train = DF_train[TARGET_COL][:-window].values \n",
    "    Y_test = DF_test[TARGET_COL][:-window].values \n",
    "    \n",
    "    return DF_train, DF_test, X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5dc86e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2 = DF.iloc[1:].reset_index(drop=True) / DF.iloc[:-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "da884d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "DF_train, DF_test, X_train, X_test, Y_train, Y_test = prepare_data(DF2,'Close',window)\n",
    "\n",
    "Y_train[Y_train>1] = 1\n",
    "Y_train[Y_train< 1] = 0\n",
    "Y_test[Y_test>1] = 1\n",
    "Y_test[Y_test< 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "febbeb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( \n",
    "    LSTM(units=32,\n",
    "         input_shape=(X_train.shape[1:]),\n",
    "         activation='relu',\n",
    "#          return_sequences=True\n",
    "        ) \n",
    ") \n",
    "model.add(Dropout(.5))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ac540d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.3161 - accuracy: 0.8543 - val_loss: 0.2317 - val_accuracy: 0.9209\n",
      "Epoch 2/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8567 - val_loss: 0.2377 - val_accuracy: 0.9096\n",
      "Epoch 3/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2536 - accuracy: 0.8987 - val_loss: 0.2658 - val_accuracy: 0.8983\n",
      "Epoch 4/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2395 - accuracy: 0.9011 - val_loss: 0.3125 - val_accuracy: 0.8644\n",
      "Epoch 5/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2579 - accuracy: 0.8837 - val_loss: 0.2024 - val_accuracy: 0.9040\n",
      "Epoch 6/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2254 - accuracy: 0.9095 - val_loss: 0.2642 - val_accuracy: 0.8983\n",
      "Epoch 7/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2970 - accuracy: 0.8681 - val_loss: 0.2316 - val_accuracy: 0.8814\n",
      "Epoch 8/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2472 - accuracy: 0.8951 - val_loss: 0.2006 - val_accuracy: 0.9266\n",
      "Epoch 9/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2419 - accuracy: 0.8945 - val_loss: 0.2132 - val_accuracy: 0.8927\n",
      "Epoch 10/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2263 - accuracy: 0.9047 - val_loss: 0.2149 - val_accuracy: 0.9096\n",
      "Epoch 11/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.3103 - accuracy: 0.8597 - val_loss: 0.2103 - val_accuracy: 0.9379\n",
      "Epoch 12/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2489 - accuracy: 0.8897 - val_loss: 0.2414 - val_accuracy: 0.8983\n",
      "Epoch 13/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2217 - accuracy: 0.9083 - val_loss: 0.2100 - val_accuracy: 0.9096\n",
      "Epoch 14/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2596 - accuracy: 0.8885 - val_loss: 0.2480 - val_accuracy: 0.8531\n",
      "Epoch 15/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.8891 - val_loss: 0.1935 - val_accuracy: 0.8983\n",
      "Epoch 16/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2203 - accuracy: 0.9083 - val_loss: 0.1946 - val_accuracy: 0.9096\n",
      "Epoch 17/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2231 - accuracy: 0.9065 - val_loss: 0.1888 - val_accuracy: 0.9096\n",
      "Epoch 18/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2458 - accuracy: 0.8897 - val_loss: 0.1892 - val_accuracy: 0.9153\n",
      "Epoch 19/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2233 - accuracy: 0.9029 - val_loss: 0.2653 - val_accuracy: 0.8927\n",
      "Epoch 20/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2694 - accuracy: 0.8813 - val_loss: 0.1912 - val_accuracy: 0.9379\n",
      "Epoch 21/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2634 - accuracy: 0.8795 - val_loss: 0.2548 - val_accuracy: 0.8814\n",
      "Epoch 22/300\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2322 - accuracy: 0.8957 - val_loss: 0.1850 - val_accuracy: 0.9266\n",
      "Epoch 23/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2317 - accuracy: 0.8939 - val_loss: 0.1843 - val_accuracy: 0.9322\n",
      "Epoch 24/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2270 - accuracy: 0.9053 - val_loss: 0.1783 - val_accuracy: 0.9266\n",
      "Epoch 25/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2102 - accuracy: 0.9095 - val_loss: 0.1731 - val_accuracy: 0.9322\n",
      "Epoch 26/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2301 - accuracy: 0.8909 - val_loss: 0.2646 - val_accuracy: 0.8927\n",
      "Epoch 27/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2409 - accuracy: 0.8957 - val_loss: 0.2166 - val_accuracy: 0.8870\n",
      "Epoch 28/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2469 - accuracy: 0.8939 - val_loss: 0.1844 - val_accuracy: 0.9322\n",
      "Epoch 29/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2056 - accuracy: 0.9137 - val_loss: 0.2148 - val_accuracy: 0.8814\n",
      "Epoch 30/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2364 - accuracy: 0.8933 - val_loss: 0.1935 - val_accuracy: 0.8983\n",
      "Epoch 31/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2463 - accuracy: 0.8927 - val_loss: 0.1770 - val_accuracy: 0.9209\n",
      "Epoch 32/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2148 - accuracy: 0.8993 - val_loss: 0.1826 - val_accuracy: 0.9322\n",
      "Epoch 33/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2575 - accuracy: 0.8843 - val_loss: 0.2568 - val_accuracy: 0.8757\n",
      "Epoch 34/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2772 - accuracy: 0.8687 - val_loss: 0.3880 - val_accuracy: 0.8023\n",
      "Epoch 35/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2471 - accuracy: 0.8885 - val_loss: 0.1889 - val_accuracy: 0.9209\n",
      "Epoch 36/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2304 - accuracy: 0.8993 - val_loss: 0.1821 - val_accuracy: 0.9379\n",
      "Epoch 37/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2387 - accuracy: 0.8813 - val_loss: 0.2400 - val_accuracy: 0.8983\n",
      "Epoch 38/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2097 - accuracy: 0.9077 - val_loss: 0.2379 - val_accuracy: 0.8870\n",
      "Epoch 39/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2184 - accuracy: 0.8933 - val_loss: 0.1739 - val_accuracy: 0.9266\n",
      "Epoch 40/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.3039 - accuracy: 0.8609 - val_loss: 0.2354 - val_accuracy: 0.8870\n",
      "Epoch 41/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2347 - accuracy: 0.8987 - val_loss: 0.1779 - val_accuracy: 0.9322\n",
      "Epoch 42/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1999 - accuracy: 0.9065 - val_loss: 0.3132 - val_accuracy: 0.8701\n",
      "Epoch 43/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2160 - accuracy: 0.9101 - val_loss: 0.2246 - val_accuracy: 0.9040\n",
      "Epoch 44/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2131 - accuracy: 0.9149 - val_loss: 0.1881 - val_accuracy: 0.8927\n",
      "Epoch 45/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.8951 - val_loss: 0.2165 - val_accuracy: 0.8927\n",
      "Epoch 46/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2114 - accuracy: 0.9065 - val_loss: 0.2239 - val_accuracy: 0.8927\n",
      "Epoch 47/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2034 - accuracy: 0.9047 - val_loss: 0.1657 - val_accuracy: 0.9266\n",
      "Epoch 48/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2057 - accuracy: 0.9029 - val_loss: 0.2544 - val_accuracy: 0.8701\n",
      "Epoch 49/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1913 - accuracy: 0.9245 - val_loss: 0.1592 - val_accuracy: 0.9379\n",
      "Epoch 50/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2056 - accuracy: 0.9119 - val_loss: 0.2511 - val_accuracy: 0.8927\n",
      "Epoch 51/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2364 - accuracy: 0.8963 - val_loss: 0.2309 - val_accuracy: 0.8927\n",
      "Epoch 52/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1845 - accuracy: 0.9269 - val_loss: 0.1935 - val_accuracy: 0.8927\n",
      "Epoch 53/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2120 - accuracy: 0.9059 - val_loss: 0.2661 - val_accuracy: 0.8757\n",
      "Epoch 54/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2253 - accuracy: 0.9077 - val_loss: 0.2560 - val_accuracy: 0.8983\n",
      "Epoch 55/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2551 - accuracy: 0.8849 - val_loss: 0.3356 - val_accuracy: 0.8475\n",
      "Epoch 56/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2584 - accuracy: 0.8765 - val_loss: 0.1927 - val_accuracy: 0.9379\n",
      "Epoch 57/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2046 - accuracy: 0.9083 - val_loss: 0.1950 - val_accuracy: 0.8870\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1891 - accuracy: 0.9197 - val_loss: 0.1613 - val_accuracy: 0.9209\n",
      "Epoch 59/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2250 - accuracy: 0.9023 - val_loss: 0.1720 - val_accuracy: 0.9266\n",
      "Epoch 60/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1965 - accuracy: 0.9173 - val_loss: 0.1618 - val_accuracy: 0.9322\n",
      "Epoch 61/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1960 - accuracy: 0.9107 - val_loss: 0.1726 - val_accuracy: 0.9209\n",
      "Epoch 62/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1974 - accuracy: 0.9197 - val_loss: 0.2180 - val_accuracy: 0.8870\n",
      "Epoch 63/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1930 - accuracy: 0.9143 - val_loss: 0.2598 - val_accuracy: 0.8927\n",
      "Epoch 64/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2128 - accuracy: 0.8969 - val_loss: 0.2535 - val_accuracy: 0.8983\n",
      "Epoch 65/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1972 - accuracy: 0.9107 - val_loss: 0.2085 - val_accuracy: 0.9040\n",
      "Epoch 66/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2021 - accuracy: 0.9029 - val_loss: 0.2028 - val_accuracy: 0.8927\n",
      "Epoch 67/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2187 - accuracy: 0.9083 - val_loss: 0.1724 - val_accuracy: 0.9209\n",
      "Epoch 68/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1835 - accuracy: 0.9263 - val_loss: 0.1627 - val_accuracy: 0.9322\n",
      "Epoch 69/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1588 - accuracy: 0.9311 - val_loss: 0.1502 - val_accuracy: 0.9435\n",
      "Epoch 70/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1735 - accuracy: 0.9335 - val_loss: 0.1759 - val_accuracy: 0.9209\n",
      "Epoch 71/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2025 - accuracy: 0.9077 - val_loss: 0.2592 - val_accuracy: 0.8701\n",
      "Epoch 72/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1877 - accuracy: 0.9167 - val_loss: 0.1509 - val_accuracy: 0.9379\n",
      "Epoch 73/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2041 - accuracy: 0.9083 - val_loss: 0.5397 - val_accuracy: 0.8305\n",
      "Epoch 74/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2150 - accuracy: 0.9113 - val_loss: 0.2457 - val_accuracy: 0.8757\n",
      "Epoch 75/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1731 - accuracy: 0.9293 - val_loss: 0.1516 - val_accuracy: 0.9266\n",
      "Epoch 76/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1740 - accuracy: 0.9269 - val_loss: 0.4125 - val_accuracy: 0.8136\n",
      "Epoch 77/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2381 - accuracy: 0.8927 - val_loss: 0.3581 - val_accuracy: 0.8418\n",
      "Epoch 78/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2115 - accuracy: 0.9071 - val_loss: 0.1616 - val_accuracy: 0.9379\n",
      "Epoch 79/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1698 - accuracy: 0.9257 - val_loss: 0.2726 - val_accuracy: 0.8983\n",
      "Epoch 80/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2458 - accuracy: 0.8795 - val_loss: 0.2231 - val_accuracy: 0.8870\n",
      "Epoch 81/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1796 - accuracy: 0.9287 - val_loss: 0.2931 - val_accuracy: 0.8757\n",
      "Epoch 82/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2264 - accuracy: 0.9029 - val_loss: 0.1716 - val_accuracy: 0.9209\n",
      "Epoch 83/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1711 - accuracy: 0.9299 - val_loss: 0.2190 - val_accuracy: 0.9040\n",
      "Epoch 84/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1682 - accuracy: 0.9305 - val_loss: 0.1490 - val_accuracy: 0.9379\n",
      "Epoch 85/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2001 - accuracy: 0.9137 - val_loss: 0.4827 - val_accuracy: 0.8475\n",
      "Epoch 86/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1898 - accuracy: 0.9173 - val_loss: 0.1630 - val_accuracy: 0.9209\n",
      "Epoch 87/300\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1947 - accuracy: 0.9119 - val_loss: 0.1885 - val_accuracy: 0.8870\n",
      "Epoch 88/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.1911 - accuracy: 0.9167 - val_loss: 0.2373 - val_accuracy: 0.8870\n",
      "Epoch 89/300\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1871 - accuracy: 0.9107 - val_loss: 0.3171 - val_accuracy: 0.8701\n",
      "Epoch 90/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2007 - accuracy: 0.9041 - val_loss: 0.2202 - val_accuracy: 0.8983\n",
      "Epoch 91/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1736 - accuracy: 0.9245 - val_loss: 0.2920 - val_accuracy: 0.8814\n",
      "Epoch 92/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.3230 - accuracy: 0.8567 - val_loss: 0.3579 - val_accuracy: 0.8362\n",
      "Epoch 93/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2431 - accuracy: 0.8813 - val_loss: 0.1961 - val_accuracy: 0.9096\n",
      "Epoch 94/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1713 - accuracy: 0.9359 - val_loss: 0.1557 - val_accuracy: 0.9266\n",
      "Epoch 95/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2155 - accuracy: 0.9107 - val_loss: 0.2505 - val_accuracy: 0.8927\n",
      "Epoch 96/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1611 - accuracy: 0.9406 - val_loss: 0.1414 - val_accuracy: 0.9492\n",
      "Epoch 97/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2027 - accuracy: 0.9131 - val_loss: 0.1808 - val_accuracy: 0.9096\n",
      "Epoch 98/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1806 - accuracy: 0.9179 - val_loss: 0.1664 - val_accuracy: 0.9096\n",
      "Epoch 99/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1501 - accuracy: 0.9406 - val_loss: 0.2267 - val_accuracy: 0.8927\n",
      "Epoch 100/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1649 - accuracy: 0.9329 - val_loss: 0.3124 - val_accuracy: 0.8870\n",
      "Epoch 101/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2308 - accuracy: 0.9047 - val_loss: 0.2078 - val_accuracy: 0.9153\n",
      "Epoch 102/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1802 - accuracy: 0.9245 - val_loss: 0.2265 - val_accuracy: 0.9040\n",
      "Epoch 103/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.3346 - accuracy: 0.8459 - val_loss: 0.2613 - val_accuracy: 0.8870\n",
      "Epoch 104/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2511 - accuracy: 0.8891 - val_loss: 0.2336 - val_accuracy: 0.8870\n",
      "Epoch 105/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2036 - accuracy: 0.9077 - val_loss: 0.1690 - val_accuracy: 0.9322\n",
      "Epoch 106/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1661 - accuracy: 0.9317 - val_loss: 0.2419 - val_accuracy: 0.8814\n",
      "Epoch 107/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1695 - accuracy: 0.9209 - val_loss: 0.1580 - val_accuracy: 0.9322\n",
      "Epoch 108/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1790 - accuracy: 0.9221 - val_loss: 0.1814 - val_accuracy: 0.9209\n",
      "Epoch 109/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.8951 - val_loss: 0.6337 - val_accuracy: 0.7627\n",
      "Epoch 110/300\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 0.2535 - accuracy: 0.8891 - val_loss: 0.1896 - val_accuracy: 0.9266\n",
      "Epoch 111/300\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.1603 - accuracy: 0.9376 - val_loss: 0.1920 - val_accuracy: 0.8983\n",
      "Epoch 112/300\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.2538 - accuracy: 0.8867 - val_loss: 0.1836 - val_accuracy: 0.9322\n",
      "Epoch 113/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1642 - accuracy: 0.9359 - val_loss: 0.1762 - val_accuracy: 0.9040\n",
      "Epoch 114/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1989 - accuracy: 0.9011 - val_loss: 0.2301 - val_accuracy: 0.8757\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1997 - accuracy: 0.9029 - val_loss: 0.1671 - val_accuracy: 0.9322\n",
      "Epoch 116/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2190 - accuracy: 0.8969 - val_loss: 0.1840 - val_accuracy: 0.9040\n",
      "Epoch 117/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1945 - accuracy: 0.9149 - val_loss: 0.5534 - val_accuracy: 0.8079\n",
      "Epoch 118/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2841 - accuracy: 0.8687 - val_loss: 0.1969 - val_accuracy: 0.9379\n",
      "Epoch 119/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1706 - accuracy: 0.9376 - val_loss: 0.1899 - val_accuracy: 0.9040\n",
      "Epoch 120/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1489 - accuracy: 0.9418 - val_loss: 0.4091 - val_accuracy: 0.8588\n",
      "Epoch 121/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1696 - accuracy: 0.9215 - val_loss: 0.1452 - val_accuracy: 0.9492\n",
      "Epoch 122/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1779 - accuracy: 0.9203 - val_loss: 0.1952 - val_accuracy: 0.9153\n",
      "Epoch 123/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1765 - accuracy: 0.9203 - val_loss: 0.3663 - val_accuracy: 0.8588\n",
      "Epoch 124/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1694 - accuracy: 0.9257 - val_loss: 0.1427 - val_accuracy: 0.9548\n",
      "Epoch 125/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1529 - accuracy: 0.9353 - val_loss: 0.5349 - val_accuracy: 0.8418\n",
      "Epoch 126/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2370 - accuracy: 0.8957 - val_loss: 0.1685 - val_accuracy: 0.9379\n",
      "Epoch 127/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1508 - accuracy: 0.9472 - val_loss: 0.1361 - val_accuracy: 0.9492\n",
      "Epoch 128/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1631 - accuracy: 0.9275 - val_loss: 0.3087 - val_accuracy: 0.8644\n",
      "Epoch 129/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2494 - accuracy: 0.8903 - val_loss: 0.3180 - val_accuracy: 0.8531\n",
      "Epoch 130/300\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.1899 - accuracy: 0.9131 - val_loss: 0.3743 - val_accuracy: 0.8192\n",
      "Epoch 131/300\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 0.1917 - accuracy: 0.9215 - val_loss: 0.1689 - val_accuracy: 0.9322\n",
      "Epoch 132/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1552 - accuracy: 0.9394 - val_loss: 0.1489 - val_accuracy: 0.9379\n",
      "Epoch 133/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1367 - accuracy: 0.9484 - val_loss: 0.1305 - val_accuracy: 0.9492\n",
      "Epoch 134/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.8525 - val_loss: 0.4121 - val_accuracy: 0.7514\n",
      "Epoch 135/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2618 - accuracy: 0.8855 - val_loss: 0.2183 - val_accuracy: 0.9322\n",
      "Epoch 136/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1908 - accuracy: 0.9400 - val_loss: 0.1778 - val_accuracy: 0.9266\n",
      "Epoch 137/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1656 - accuracy: 0.9299 - val_loss: 0.2026 - val_accuracy: 0.9096\n",
      "Epoch 138/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1499 - accuracy: 0.9454 - val_loss: 0.1548 - val_accuracy: 0.9322\n",
      "Epoch 139/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1405 - accuracy: 0.9359 - val_loss: 0.2451 - val_accuracy: 0.9096\n",
      "Epoch 140/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1909 - accuracy: 0.9161 - val_loss: 0.1411 - val_accuracy: 0.9435\n",
      "Epoch 141/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1377 - accuracy: 0.9436 - val_loss: 0.1324 - val_accuracy: 0.9492\n",
      "Epoch 142/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2911 - accuracy: 0.8843 - val_loss: 0.1797 - val_accuracy: 0.9040\n",
      "Epoch 143/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1905 - accuracy: 0.9179 - val_loss: 0.1610 - val_accuracy: 0.9322\n",
      "Epoch 144/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1897 - val_accuracy: 0.9153\n",
      "Epoch 145/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1333 - accuracy: 0.9436 - val_loss: 0.1743 - val_accuracy: 0.9266\n",
      "Epoch 146/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1253 - accuracy: 0.9532 - val_loss: 0.1770 - val_accuracy: 0.9209\n",
      "Epoch 147/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1329 - accuracy: 0.9514 - val_loss: 0.2527 - val_accuracy: 0.8814\n",
      "Epoch 148/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2093 - accuracy: 0.9161 - val_loss: 0.1303 - val_accuracy: 0.9435\n",
      "Epoch 149/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1635 - accuracy: 0.9233 - val_loss: 0.1277 - val_accuracy: 0.9492\n",
      "Epoch 150/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1586 - accuracy: 0.9394 - val_loss: 0.1424 - val_accuracy: 0.9322\n",
      "Epoch 151/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1502 - accuracy: 0.9299 - val_loss: 0.1825 - val_accuracy: 0.9322\n",
      "Epoch 152/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1784 - accuracy: 0.9233 - val_loss: 0.1572 - val_accuracy: 0.9435\n",
      "Epoch 153/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1752 - accuracy: 0.9215 - val_loss: 0.1252 - val_accuracy: 0.9548\n",
      "Epoch 154/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1466 - accuracy: 0.9347 - val_loss: 0.1218 - val_accuracy: 0.9492\n",
      "Epoch 155/300\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1506 - accuracy: 0.9400 - val_loss: 0.1188 - val_accuracy: 0.9548\n",
      "Epoch 156/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1379 - accuracy: 0.9472 - val_loss: 0.1283 - val_accuracy: 0.9435\n",
      "Epoch 157/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1769 - accuracy: 0.9317 - val_loss: 0.1195 - val_accuracy: 0.9492\n",
      "Epoch 158/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1533 - accuracy: 0.9341 - val_loss: 0.1357 - val_accuracy: 0.9379\n",
      "Epoch 159/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1235 - accuracy: 0.9550 - val_loss: 0.1174 - val_accuracy: 0.9492\n",
      "Epoch 160/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1594 - accuracy: 0.9341 - val_loss: 0.4114 - val_accuracy: 0.8588\n",
      "Epoch 161/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1298 - accuracy: 0.9466 - val_loss: 0.1188 - val_accuracy: 0.9548\n",
      "Epoch 162/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1320 - accuracy: 0.9418 - val_loss: 0.1791 - val_accuracy: 0.9379\n",
      "Epoch 163/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.9400 - val_loss: 0.4246 - val_accuracy: 0.8588\n",
      "Epoch 164/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1706 - accuracy: 0.9209 - val_loss: 0.2599 - val_accuracy: 0.9209\n",
      "Epoch 165/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 0.9406 - val_loss: 0.1997 - val_accuracy: 0.9266\n",
      "Epoch 166/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2229 - accuracy: 0.9005 - val_loss: 0.2128 - val_accuracy: 0.9209\n",
      "Epoch 167/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1416 - accuracy: 0.9376 - val_loss: 0.2532 - val_accuracy: 0.8983\n",
      "Epoch 168/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1332 - accuracy: 0.9508 - val_loss: 0.1262 - val_accuracy: 0.9605\n",
      "Epoch 169/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1443 - accuracy: 0.9376 - val_loss: 0.2436 - val_accuracy: 0.9153\n",
      "Epoch 170/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2782 - accuracy: 0.9047 - val_loss: 0.4538 - val_accuracy: 0.8362\n",
      "Epoch 171/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2028 - accuracy: 0.9035 - val_loss: 0.1765 - val_accuracy: 0.9209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1458 - accuracy: 0.9508 - val_loss: 0.1445 - val_accuracy: 0.9266\n",
      "Epoch 173/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9394 - val_loss: 0.1317 - val_accuracy: 0.9548\n",
      "Epoch 174/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1408 - accuracy: 0.9382 - val_loss: 0.1550 - val_accuracy: 0.9153\n",
      "Epoch 175/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1461 - accuracy: 0.9347 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 176/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1695 - accuracy: 0.9275 - val_loss: 0.7012 - val_accuracy: 0.7853\n",
      "Epoch 177/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.4229 - accuracy: 0.8831 - val_loss: 0.2328 - val_accuracy: 0.9096\n",
      "Epoch 178/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1769 - accuracy: 0.9388 - val_loss: 0.1806 - val_accuracy: 0.8870\n",
      "Epoch 179/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1602 - accuracy: 0.9406 - val_loss: 0.1559 - val_accuracy: 0.9322\n",
      "Epoch 180/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1265 - accuracy: 0.9568 - val_loss: 0.1219 - val_accuracy: 0.9605\n",
      "Epoch 181/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1308 - accuracy: 0.9526 - val_loss: 0.1204 - val_accuracy: 0.9605\n",
      "Epoch 182/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9436 - val_loss: 0.1144 - val_accuracy: 0.9605\n",
      "Epoch 183/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1379 - accuracy: 0.9365 - val_loss: 0.3002 - val_accuracy: 0.8757\n",
      "Epoch 184/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1523 - accuracy: 0.9311 - val_loss: 0.1283 - val_accuracy: 0.9605\n",
      "Epoch 185/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1249 - accuracy: 0.9520 - val_loss: 0.1172 - val_accuracy: 0.9661\n",
      "Epoch 186/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1116 - accuracy: 0.9574 - val_loss: 0.1187 - val_accuracy: 0.9435\n",
      "Epoch 187/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.9580 - val_loss: 0.2482 - val_accuracy: 0.8870\n",
      "Epoch 188/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1259 - accuracy: 0.9472 - val_loss: 0.1440 - val_accuracy: 0.9379\n",
      "Epoch 189/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1015 - accuracy: 0.9544 - val_loss: 0.3660 - val_accuracy: 0.8983\n",
      "Epoch 190/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1839 - accuracy: 0.9197 - val_loss: 0.1859 - val_accuracy: 0.9040\n",
      "Epoch 191/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1379 - accuracy: 0.9412 - val_loss: 0.1372 - val_accuracy: 0.9322\n",
      "Epoch 192/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2684 - accuracy: 0.8915 - val_loss: 0.1713 - val_accuracy: 0.9096\n",
      "Epoch 193/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2009 - accuracy: 0.9083 - val_loss: 0.1401 - val_accuracy: 0.9548\n",
      "Epoch 194/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1886 - accuracy: 0.9029 - val_loss: 0.1446 - val_accuracy: 0.9322\n",
      "Epoch 195/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1370 - accuracy: 0.9436 - val_loss: 0.2038 - val_accuracy: 0.9209\n",
      "Epoch 196/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1575 - accuracy: 0.9245 - val_loss: 0.1364 - val_accuracy: 0.9322\n",
      "Epoch 197/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9359 - val_loss: 0.1605 - val_accuracy: 0.9322\n",
      "Epoch 198/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1329 - accuracy: 0.9436 - val_loss: 0.1624 - val_accuracy: 0.9322\n",
      "Epoch 199/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1577 - accuracy: 0.9335 - val_loss: 0.1451 - val_accuracy: 0.9379\n",
      "Epoch 200/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 0.9532 - val_loss: 0.1024 - val_accuracy: 0.9661\n",
      "Epoch 201/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1700 - accuracy: 0.9197 - val_loss: 0.1463 - val_accuracy: 0.9322\n",
      "Epoch 202/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1123 - accuracy: 0.9592 - val_loss: 0.1111 - val_accuracy: 0.9661\n",
      "Epoch 203/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.9658 - val_loss: 0.1208 - val_accuracy: 0.9435\n",
      "Epoch 204/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1986 - accuracy: 0.9299 - val_loss: 0.2373 - val_accuracy: 0.9379\n",
      "Epoch 205/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.2213 - accuracy: 0.9155 - val_loss: 0.1614 - val_accuracy: 0.9435\n",
      "Epoch 206/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1445 - accuracy: 0.9484 - val_loss: 0.2212 - val_accuracy: 0.9266\n",
      "Epoch 207/300\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1297 - accuracy: 0.9466 - val_loss: 0.1425 - val_accuracy: 0.9266\n",
      "Epoch 208/300\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1511 - accuracy: 0.9359 - val_loss: 0.1202 - val_accuracy: 0.9435\n",
      "Epoch 209/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1325 - accuracy: 0.9371 - val_loss: 0.2086 - val_accuracy: 0.8814\n",
      "Epoch 210/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1617 - accuracy: 0.9287 - val_loss: 0.1867 - val_accuracy: 0.9379\n",
      "Epoch 211/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1284 - accuracy: 0.9406 - val_loss: 0.1284 - val_accuracy: 0.9379\n",
      "Epoch 212/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1159 - accuracy: 0.9508 - val_loss: 0.3353 - val_accuracy: 0.9040\n",
      "Epoch 213/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1148 - accuracy: 0.9550 - val_loss: 0.1083 - val_accuracy: 0.9492\n",
      "Epoch 214/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2321 - accuracy: 0.9077 - val_loss: 0.1463 - val_accuracy: 0.9209\n",
      "Epoch 215/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1638 - accuracy: 0.9305 - val_loss: 0.2227 - val_accuracy: 0.9096\n",
      "Epoch 216/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.9323 - val_loss: 0.1583 - val_accuracy: 0.9096\n",
      "Epoch 217/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1861 - accuracy: 0.9083 - val_loss: 0.1526 - val_accuracy: 0.9322\n",
      "Epoch 218/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1448 - accuracy: 0.9388 - val_loss: 0.1187 - val_accuracy: 0.9492\n",
      "Epoch 219/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9586 - val_loss: 0.1435 - val_accuracy: 0.9209\n",
      "Epoch 220/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1287 - accuracy: 0.9430 - val_loss: 0.1033 - val_accuracy: 0.9605\n",
      "Epoch 221/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1466 - accuracy: 0.9287 - val_loss: 0.1661 - val_accuracy: 0.9322\n",
      "Epoch 222/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1436 - accuracy: 0.9430 - val_loss: 0.4071 - val_accuracy: 0.8362\n",
      "Epoch 223/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2028 - accuracy: 0.9203 - val_loss: 0.1191 - val_accuracy: 0.9605\n",
      "Epoch 224/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.2008 - val_accuracy: 0.9209\n",
      "Epoch 225/300\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1404 - accuracy: 0.9418 - val_loss: 0.5980 - val_accuracy: 0.7966\n",
      "Epoch 226/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2082 - accuracy: 0.9137 - val_loss: 0.1288 - val_accuracy: 0.9435\n",
      "Epoch 227/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1233 - accuracy: 0.9550 - val_loss: 0.1114 - val_accuracy: 0.9435\n",
      "Epoch 228/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1106 - accuracy: 0.9604 - val_loss: 0.1028 - val_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1146 - accuracy: 0.9448 - val_loss: 0.2340 - val_accuracy: 0.8814\n",
      "Epoch 230/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1668 - accuracy: 0.9311 - val_loss: 0.1221 - val_accuracy: 0.9492\n",
      "Epoch 231/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1933 - accuracy: 0.9245 - val_loss: 0.2555 - val_accuracy: 0.8983\n",
      "Epoch 232/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.4119 - accuracy: 0.8321 - val_loss: 0.3204 - val_accuracy: 0.8701\n",
      "Epoch 233/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1917 - accuracy: 0.9263 - val_loss: 0.1550 - val_accuracy: 0.9435\n",
      "Epoch 234/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1396 - accuracy: 0.9574 - val_loss: 0.1209 - val_accuracy: 0.9605\n",
      "Epoch 235/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1160 - accuracy: 0.9610 - val_loss: 0.1083 - val_accuracy: 0.9435\n",
      "Epoch 236/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1299 - accuracy: 0.9418 - val_loss: 0.3591 - val_accuracy: 0.8870\n",
      "Epoch 237/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1771 - accuracy: 0.9215 - val_loss: 0.1087 - val_accuracy: 0.9718\n",
      "Epoch 238/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1381 - accuracy: 0.9388 - val_loss: 0.1048 - val_accuracy: 0.9718\n",
      "Epoch 239/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1715 - accuracy: 0.9215 - val_loss: 0.2374 - val_accuracy: 0.9096\n",
      "Epoch 240/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1741 - accuracy: 0.9047 - val_loss: 0.1109 - val_accuracy: 0.9774\n",
      "Epoch 241/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1432 - accuracy: 0.9365 - val_loss: 0.1178 - val_accuracy: 0.9435\n",
      "Epoch 242/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1122 - accuracy: 0.9544 - val_loss: 0.1079 - val_accuracy: 0.9435\n",
      "Epoch 243/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1070 - accuracy: 0.9544 - val_loss: 0.1244 - val_accuracy: 0.9322\n",
      "Epoch 244/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1159 - accuracy: 0.9562 - val_loss: 0.1059 - val_accuracy: 0.9492\n",
      "Epoch 245/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1281 - accuracy: 0.9382 - val_loss: 0.1052 - val_accuracy: 0.9548\n",
      "Epoch 246/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1264 - accuracy: 0.9400 - val_loss: 0.1856 - val_accuracy: 0.9040\n",
      "Epoch 247/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1166 - accuracy: 0.9514 - val_loss: 0.1229 - val_accuracy: 0.9435\n",
      "Epoch 248/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1681 - accuracy: 0.9305 - val_loss: 0.1276 - val_accuracy: 0.9435\n",
      "Epoch 249/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1563 - accuracy: 0.9382 - val_loss: 0.1048 - val_accuracy: 0.9661\n",
      "Epoch 250/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0987 - accuracy: 0.9640 - val_loss: 0.1030 - val_accuracy: 0.9661\n",
      "Epoch 251/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0973 - accuracy: 0.9676 - val_loss: 0.0925 - val_accuracy: 0.9605\n",
      "Epoch 252/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1308 - accuracy: 0.9424 - val_loss: 0.1045 - val_accuracy: 0.9548\n",
      "Epoch 253/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1026 - accuracy: 0.9610 - val_loss: 0.1334 - val_accuracy: 0.9266\n",
      "Epoch 254/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1067 - accuracy: 0.9472 - val_loss: 0.0872 - val_accuracy: 0.9718\n",
      "Epoch 255/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0971 - accuracy: 0.9616 - val_loss: 0.0897 - val_accuracy: 0.9605\n",
      "Epoch 256/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1415 - accuracy: 0.9412 - val_loss: 0.2735 - val_accuracy: 0.8927\n",
      "Epoch 257/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1117 - accuracy: 0.9550 - val_loss: 0.1347 - val_accuracy: 0.9266\n",
      "Epoch 258/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1046 - accuracy: 0.9550 - val_loss: 0.3747 - val_accuracy: 0.8870\n",
      "Epoch 259/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2210 - accuracy: 0.9065 - val_loss: 0.1298 - val_accuracy: 0.9492\n",
      "Epoch 260/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1881 - accuracy: 0.9113 - val_loss: 0.1288 - val_accuracy: 0.9379\n",
      "Epoch 261/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1036 - accuracy: 0.9688 - val_loss: 0.2317 - val_accuracy: 0.8983\n",
      "Epoch 262/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.3117 - accuracy: 0.8693 - val_loss: 0.1791 - val_accuracy: 0.8983\n",
      "Epoch 263/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1519 - accuracy: 0.9388 - val_loss: 0.1265 - val_accuracy: 0.9661\n",
      "Epoch 264/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1382 - accuracy: 0.9436 - val_loss: 0.1102 - val_accuracy: 0.9605\n",
      "Epoch 265/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1122 - accuracy: 0.9580 - val_loss: 0.0980 - val_accuracy: 0.9661\n",
      "Epoch 266/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1796 - accuracy: 0.9149 - val_loss: 0.6301 - val_accuracy: 0.8305\n",
      "Epoch 267/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.3008 - accuracy: 0.8699 - val_loss: 0.1435 - val_accuracy: 0.9492\n",
      "Epoch 268/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1800 - accuracy: 0.9143 - val_loss: 0.1571 - val_accuracy: 0.9322\n",
      "Epoch 269/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1507 - accuracy: 0.9263 - val_loss: 0.1179 - val_accuracy: 0.9661\n",
      "Epoch 270/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1149 - accuracy: 0.9640 - val_loss: 0.1070 - val_accuracy: 0.9774\n",
      "Epoch 271/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1361 - accuracy: 0.9400 - val_loss: 0.5446 - val_accuracy: 0.8362\n",
      "Epoch 272/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1546 - accuracy: 0.9418 - val_loss: 0.1167 - val_accuracy: 0.9548\n",
      "Epoch 273/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1123 - accuracy: 0.9550 - val_loss: 0.1103 - val_accuracy: 0.9379\n",
      "Epoch 274/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0914 - accuracy: 0.9706 - val_loss: 0.0860 - val_accuracy: 0.9492\n",
      "Epoch 275/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0988 - accuracy: 0.9592 - val_loss: 0.0853 - val_accuracy: 0.9605\n",
      "Epoch 276/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.9580 - val_loss: 0.2766 - val_accuracy: 0.9209\n",
      "Epoch 277/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1651 - accuracy: 0.9341 - val_loss: 0.3114 - val_accuracy: 0.8927\n",
      "Epoch 278/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1242 - accuracy: 0.9478 - val_loss: 0.1098 - val_accuracy: 0.9435\n",
      "Epoch 279/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1375 - accuracy: 0.9418 - val_loss: 0.1909 - val_accuracy: 0.8927\n",
      "Epoch 280/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1248 - accuracy: 0.9388 - val_loss: 0.1013 - val_accuracy: 0.9548\n",
      "Epoch 281/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 0.9682 - val_loss: 0.0860 - val_accuracy: 0.9831\n",
      "Epoch 282/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0982 - accuracy: 0.9616 - val_loss: 0.0878 - val_accuracy: 0.9774\n",
      "Epoch 283/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0953 - accuracy: 0.9616 - val_loss: 0.0886 - val_accuracy: 0.9661\n",
      "Epoch 284/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0753 - accuracy: 0.9688 - val_loss: 0.1509 - val_accuracy: 0.9209\n",
      "Epoch 285/300\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1779 - accuracy: 0.9353 - val_loss: 0.1724 - val_accuracy: 0.9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0896 - accuracy: 0.9628 - val_loss: 0.1007 - val_accuracy: 0.9492\n",
      "Epoch 287/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0961 - accuracy: 0.9562 - val_loss: 0.1408 - val_accuracy: 0.9435\n",
      "Epoch 288/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1701 - accuracy: 0.9424 - val_loss: 0.1013 - val_accuracy: 0.9605\n",
      "Epoch 289/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1005 - accuracy: 0.9550 - val_loss: 0.0877 - val_accuracy: 0.9774\n",
      "Epoch 290/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1591 - accuracy: 0.9269 - val_loss: 0.1028 - val_accuracy: 0.9605\n",
      "Epoch 291/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1043 - accuracy: 0.9568 - val_loss: 0.1026 - val_accuracy: 0.9548\n",
      "Epoch 292/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1193 - accuracy: 0.9508 - val_loss: 0.2656 - val_accuracy: 0.8701\n",
      "Epoch 293/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1202 - accuracy: 0.9448 - val_loss: 0.1195 - val_accuracy: 0.9435\n",
      "Epoch 294/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0925 - accuracy: 0.9604 - val_loss: 0.1589 - val_accuracy: 0.9322\n",
      "Epoch 295/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1057 - accuracy: 0.9502 - val_loss: 0.1543 - val_accuracy: 0.9435\n",
      "Epoch 296/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.9442 - val_loss: 0.1891 - val_accuracy: 0.9379\n",
      "Epoch 297/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0992 - accuracy: 0.9604 - val_loss: 0.1502 - val_accuracy: 0.9096\n",
      "Epoch 298/300\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1901 - accuracy: 0.9155 - val_loss: 0.1126 - val_accuracy: 0.9661\n",
      "Epoch 299/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1019 - accuracy: 0.9622 - val_loss: 0.0913 - val_accuracy: 0.9718\n",
      "Epoch 300/300\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9646 - val_loss: 0.1080 - val_accuracy: 0.9435\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, epochs=300,batch_size=50, validation_data=(X_test,Y_test), shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "77eaebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95        88\n",
      "         1.0       0.99      0.90      0.94        89\n",
      "\n",
      "    accuracy                           0.94       177\n",
      "   macro avg       0.95      0.94      0.94       177\n",
      "weighted avg       0.95      0.94      0.94       177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_predict = model.predict(X_test)\n",
    "Y_predict[Y_predict > 0.5] = 1\n",
    "Y_predict[Y_predict <= 0.5] = 0\n",
    "# Y_predict = [np.argmax(x) for x in Y_predict]\n",
    "print(metrics.classification_report(Y_test,Y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb952c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93419b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3a576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "be8b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( \n",
    "    LSTM(units=32,\n",
    "         input_shape=(X_train.shape[1:]),\n",
    "         activation='relu',\n",
    "#          return_sequences=True\n",
    "        ) \n",
    ") \n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(10))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(loss='mse',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e5adbcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 3s 17ms/step - loss: 0.3222 - accuracy: 0.5054 - val_loss: 0.2518 - val_accuracy: 0.4689\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2530 - accuracy: 0.5132 - val_loss: 0.2516 - val_accuracy: 0.4915\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2498 - accuracy: 0.5348 - val_loss: 0.2499 - val_accuracy: 0.4746\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2494 - accuracy: 0.5090 - val_loss: 0.2494 - val_accuracy: 0.4972\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2470 - accuracy: 0.5354 - val_loss: 0.2473 - val_accuracy: 0.5932\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2473 - accuracy: 0.5222 - val_loss: 0.2469 - val_accuracy: 0.5198\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2437 - accuracy: 0.5600 - val_loss: 0.2430 - val_accuracy: 0.5480\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2403 - accuracy: 0.5911 - val_loss: 0.2382 - val_accuracy: 0.5876\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2393 - accuracy: 0.5935 - val_loss: 0.2334 - val_accuracy: 0.6384\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2388 - accuracy: 0.5827 - val_loss: 0.2299 - val_accuracy: 0.7062\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2334 - accuracy: 0.6073 - val_loss: 0.2284 - val_accuracy: 0.6102\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2296 - accuracy: 0.6151 - val_loss: 0.2267 - val_accuracy: 0.5819\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2307 - accuracy: 0.5887 - val_loss: 0.2371 - val_accuracy: 0.5593\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2243 - accuracy: 0.6493 - val_loss: 0.2233 - val_accuracy: 0.5763\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2206 - accuracy: 0.6241 - val_loss: 0.2061 - val_accuracy: 0.7119\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2106 - accuracy: 0.6906 - val_loss: 0.2043 - val_accuracy: 0.6497\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2153 - accuracy: 0.6367 - val_loss: 0.2092 - val_accuracy: 0.5989\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2003 - accuracy: 0.6918 - val_loss: 0.1973 - val_accuracy: 0.6497\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1917 - accuracy: 0.7026 - val_loss: 0.1742 - val_accuracy: 0.8023\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1736 - accuracy: 0.7836 - val_loss: 0.2869 - val_accuracy: 0.5367\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1896 - accuracy: 0.7158 - val_loss: 0.2031 - val_accuracy: 0.6215\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1892 - accuracy: 0.6942 - val_loss: 0.1630 - val_accuracy: 0.8079\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1642 - accuracy: 0.7998 - val_loss: 0.1830 - val_accuracy: 0.6949\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1549 - accuracy: 0.7962 - val_loss: 0.1585 - val_accuracy: 0.7458\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1546 - accuracy: 0.7788 - val_loss: 0.1388 - val_accuracy: 0.8192\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1538 - accuracy: 0.7872 - val_loss: 0.2086 - val_accuracy: 0.6723\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1508 - accuracy: 0.7914 - val_loss: 0.1396 - val_accuracy: 0.7853\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.7968 - val_loss: 0.1302 - val_accuracy: 0.8192\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.7686 - val_loss: 0.1761 - val_accuracy: 0.6893\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1458 - accuracy: 0.7986 - val_loss: 0.1289 - val_accuracy: 0.8192\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1420 - accuracy: 0.8046 - val_loss: 0.1390 - val_accuracy: 0.8362\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1491 - accuracy: 0.7950 - val_loss: 0.1305 - val_accuracy: 0.8305\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 0.8297 - val_loss: 0.1241 - val_accuracy: 0.8588\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1255 - accuracy: 0.8309 - val_loss: 0.1186 - val_accuracy: 0.8305\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1331 - accuracy: 0.8171 - val_loss: 0.1348 - val_accuracy: 0.7910\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.8034 - val_loss: 0.1198 - val_accuracy: 0.8249\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1249 - accuracy: 0.8387 - val_loss: 0.1474 - val_accuracy: 0.7684\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1248 - accuracy: 0.8279 - val_loss: 0.1596 - val_accuracy: 0.7514\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1309 - accuracy: 0.8237 - val_loss: 0.1487 - val_accuracy: 0.7684\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1277 - accuracy: 0.8112 - val_loss: 0.1087 - val_accuracy: 0.8418\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1189 - accuracy: 0.8327 - val_loss: 0.1488 - val_accuracy: 0.7797\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1660 - accuracy: 0.7428 - val_loss: 0.1234 - val_accuracy: 0.8136\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1262 - accuracy: 0.8219 - val_loss: 0.1391 - val_accuracy: 0.7740\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1273 - accuracy: 0.8255 - val_loss: 0.1183 - val_accuracy: 0.8249\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1492 - accuracy: 0.7800 - val_loss: 0.1110 - val_accuracy: 0.8531\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1233 - accuracy: 0.8387 - val_loss: 0.1440 - val_accuracy: 0.7627\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1336 - accuracy: 0.8100 - val_loss: 0.1099 - val_accuracy: 0.8531\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 0.8543 - val_loss: 0.1111 - val_accuracy: 0.8362\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1181 - accuracy: 0.8411 - val_loss: 0.1041 - val_accuracy: 0.8588\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1182 - accuracy: 0.8399 - val_loss: 0.1878 - val_accuracy: 0.7232\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1262 - accuracy: 0.8261 - val_loss: 0.1170 - val_accuracy: 0.8192\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1172 - accuracy: 0.8363 - val_loss: 0.1302 - val_accuracy: 0.7966\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1187 - accuracy: 0.8351 - val_loss: 0.1025 - val_accuracy: 0.8531\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1175 - accuracy: 0.8375 - val_loss: 0.1080 - val_accuracy: 0.8644\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1119 - accuracy: 0.8519 - val_loss: 0.1114 - val_accuracy: 0.8305\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1398 - accuracy: 0.8016 - val_loss: 0.0961 - val_accuracy: 0.8644\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1102 - accuracy: 0.8483 - val_loss: 0.0966 - val_accuracy: 0.8588\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.8417 - val_loss: 0.0947 - val_accuracy: 0.8644\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1021 - accuracy: 0.8717 - val_loss: 0.0968 - val_accuracy: 0.8588\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1024 - accuracy: 0.8591 - val_loss: 0.1052 - val_accuracy: 0.8362\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1238 - accuracy: 0.8231 - val_loss: 0.0983 - val_accuracy: 0.8588\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1154 - accuracy: 0.8351 - val_loss: 0.1403 - val_accuracy: 0.7627\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.8369 - val_loss: 0.0991 - val_accuracy: 0.8588\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1049 - accuracy: 0.8555 - val_loss: 0.0929 - val_accuracy: 0.8644\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1104 - accuracy: 0.8525 - val_loss: 0.1257 - val_accuracy: 0.8079\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1039 - accuracy: 0.8549 - val_loss: 0.1679 - val_accuracy: 0.7684\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1144 - accuracy: 0.8405 - val_loss: 0.1140 - val_accuracy: 0.8362\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1011 - accuracy: 0.8651 - val_loss: 0.1033 - val_accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1083 - accuracy: 0.8477 - val_loss: 0.0947 - val_accuracy: 0.8644\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1329 - accuracy: 0.8147 - val_loss: 0.1142 - val_accuracy: 0.8418\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1042 - accuracy: 0.8609 - val_loss: 0.0971 - val_accuracy: 0.8701\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0992 - accuracy: 0.8765 - val_loss: 0.0899 - val_accuracy: 0.8701\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.8609 - val_loss: 0.1052 - val_accuracy: 0.8644\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1055 - accuracy: 0.8483 - val_loss: 0.1037 - val_accuracy: 0.8531\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 0.8639 - val_loss: 0.1057 - val_accuracy: 0.8475\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.8669 - val_loss: 0.1203 - val_accuracy: 0.8305\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1194 - accuracy: 0.8417 - val_loss: 0.1034 - val_accuracy: 0.8418\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.8639 - val_loss: 0.0969 - val_accuracy: 0.8757\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1062 - accuracy: 0.8513 - val_loss: 0.1043 - val_accuracy: 0.8588\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0978 - accuracy: 0.8675 - val_loss: 0.1040 - val_accuracy: 0.8588\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0999 - accuracy: 0.8615 - val_loss: 0.1384 - val_accuracy: 0.7966\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1455 - accuracy: 0.7950 - val_loss: 0.1502 - val_accuracy: 0.7740\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.1345 - accuracy: 0.7998 - val_loss: 0.1310 - val_accuracy: 0.7966\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1022 - accuracy: 0.8729 - val_loss: 0.0957 - val_accuracy: 0.8588\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1013 - accuracy: 0.8591 - val_loss: 0.1005 - val_accuracy: 0.8531\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0962 - accuracy: 0.8609 - val_loss: 0.0912 - val_accuracy: 0.8701\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0941 - accuracy: 0.8729 - val_loss: 0.1104 - val_accuracy: 0.8418\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0968 - accuracy: 0.8591 - val_loss: 0.0832 - val_accuracy: 0.8701\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0975 - accuracy: 0.8657 - val_loss: 0.0861 - val_accuracy: 0.8870\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0957 - accuracy: 0.8687 - val_loss: 0.0934 - val_accuracy: 0.8644\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1063 - accuracy: 0.8453 - val_loss: 0.0838 - val_accuracy: 0.8701\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0920 - accuracy: 0.8717 - val_loss: 0.0906 - val_accuracy: 0.8701\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1169 - accuracy: 0.8399 - val_loss: 0.0979 - val_accuracy: 0.8531\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0933 - accuracy: 0.8753 - val_loss: 0.0868 - val_accuracy: 0.8757\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0975 - accuracy: 0.8663 - val_loss: 0.1393 - val_accuracy: 0.7740\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1073 - accuracy: 0.8435 - val_loss: 0.0924 - val_accuracy: 0.8701\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.8483 - val_loss: 0.0864 - val_accuracy: 0.8814\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1134 - accuracy: 0.8435 - val_loss: 0.0849 - val_accuracy: 0.8757\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0911 - accuracy: 0.8807 - val_loss: 0.0849 - val_accuracy: 0.8757\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0921 - accuracy: 0.8717 - val_loss: 0.0844 - val_accuracy: 0.8757\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, epochs=100,batch_size=50, validation_data=(X_test,Y_test), shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5e6eaf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6623234641536087"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = model.predict(X_test)\n",
    "# Y_predict[Y_predict > 0.5] = 1\n",
    "# Y_predict[Y_predict <= 0.5] = 0\n",
    "# Y_predict = [np.argmax(x) for x in Y_predict]\n",
    "metrics.r2_score(y_pred=Y_predict,y_true=Y_test )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
