{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7afbf9db",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">AdaBoost Classification (ensemble method)</font>\n",
    "<ul>\n",
    "<li><p><strong>AdaBoost or Adaptive Boosting</strong> is one of the ensemble boosting classifier proposed by Yoav Freund and Robert Schapire in 1996.</p>\n",
    "</li>\n",
    "<li><p>It combines multiple weak classifiers to increase the accuracy of classifiers.</p>\n",
    "</li>\n",
    "<li><p>AdaBoost is an iterative ensemble method. AdaBoost classifier builds a strong classifier by combining multiple poorly performing classifiers so that you will get high accuracy strong classifier.</p>\n",
    "</li>\n",
    "<li><p>The basic concept behind Adaboost is to set the weights of classifiers and training the data sample in each iteration such that it ensures the accurate predictions of unusual observations.</p>\n",
    "</li>\n",
    "<li><p>Any machine learning algorithm can be used as base classifier if it accepts weights on the training set.</p>\n",
    "</li>\n",
    "<li><p><strong>AdaBoost</strong> should meet two conditions:</p>\n",
    "<ol>\n",
    "<li><p>The classifier should be trained interactively on various weighed training examples.</p>\n",
    "</li>\n",
    "<li><p>In each iteration, it tries to provide an excellent fit for these examples by minimizing training error.</p>\n",
    "</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "<li><p>To build a AdaBoost classifier, imagine that as a first base classifier we train a Decision Tree algorithm to make predictions on our training data.</p>\n",
    "</li>\n",
    "<li><p>Now, following the methodology of AdaBoost, the weight of the misclassified training instances is increased.</p>\n",
    "</li>\n",
    "<li><p>The second classifier is trained and acknowledges the updated weights and it repeats the procedure over and over again.</p>\n",
    "</li>\n",
    "<li><p>At the end of every model prediction we end up boosting the weights of the misclassified instances so that the next model does a better job on them, and so on.</p>\n",
    "</li>\n",
    "<li><p>AdaBoost adds predictors to the ensemble gradually making it better. The great disadvantage of this algorithm is that the model cannot be parallelized since each predictor can only be trained after the previous one has been trained and evaluated.</p>\n",
    "</li>\n",
    "<li><p>Below are the steps for performing the AdaBoost algorithm:</p>\n",
    "<ol>\n",
    "<li><p>Initially, all observations are given equal weights.</p>\n",
    "</li>\n",
    "<li><p>A model is built on a subset of data.</p>\n",
    "</li>\n",
    "<li><p>Using this model, predictions are made on the whole dataset.</p>\n",
    "</li>\n",
    "<li><p>Errors are calculated by comparing the predictions and actual values.</p>\n",
    "</li>\n",
    "<li><p>While creating the next model, higher weights are given to the data points which were predicted incorrectly.</p>\n",
    "</li>\n",
    "<li><p>Weights can be determined using the error value. For instance,the higher the error the more is the weight assigned to the observation.</p>\n",
    "</li>\n",
    "<li><p>This process is repeated until the error function does not change, or the maximum limit of the number of estimators is reached.</p>\n",
    "</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<img src=\"../../../img/image_3_nwa5zf.webp\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e33d34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as PLT, cm as CMAP\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01928090",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8273cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DT.images.reshape(len(DT.images),-1)\n",
    "Y = DT.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4acbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93        79\n",
      "           1       0.00      0.00      0.00        80\n",
      "           2       0.00      0.00      0.00        77\n",
      "           3       0.13      0.97      0.22        79\n",
      "           4       0.00      0.00      0.00        83\n",
      "           5       0.00      0.00      0.00        82\n",
      "           6       0.47      0.34      0.39        80\n",
      "           7       0.00      0.00      0.00        80\n",
      "           8       0.00      0.00      0.00        76\n",
      "           9       0.76      0.38      0.51        81\n",
      "\n",
      "    accuracy                           0.26       797\n",
      "   macro avg       0.22      0.27      0.20       797\n",
      "weighted avg       0.22      0.26      0.20       797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "random_forest_classifier = AdaBoostClassifier(n_estimators=1000)\n",
    "random_forest_classifier.fit(X[:1000],Y[:1000])\n",
    "\n",
    "predicted = random_forest_classifier.predict(X[1000:])\n",
    "expected = Y[1000:]\n",
    "\n",
    "report = metrics.classification_report(expected,predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a3b9817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=SVC(kernel='linear', probability=True),\n",
       "                   n_estimators=500)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier = AdaBoostClassifier(base_estimator=SVC(probability=True,kernel='linear'),n_estimators=500)\n",
    "random_forest_classifier.fit(X[:1000],Y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43a6eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        79\n",
      "           1       0.96      0.89      0.92        80\n",
      "           2       1.00      0.99      0.99        77\n",
      "           3       0.97      0.84      0.90        79\n",
      "           4       0.98      0.95      0.96        83\n",
      "           5       0.92      0.99      0.95        82\n",
      "           6       0.99      0.99      0.99        80\n",
      "           7       0.94      0.96      0.95        80\n",
      "           8       0.89      0.93      0.91        76\n",
      "           9       0.86      0.95      0.90        81\n",
      "\n",
      "    accuracy                           0.95       797\n",
      "   macro avg       0.95      0.95      0.95       797\n",
      "weighted avg       0.95      0.95      0.95       797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = random_forest_classifier.predict(X[1000:])\n",
    "expected = Y[1000:]\n",
    "\n",
    "report = metrics.classification_report(expected,predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e5e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f617e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252cc2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a6660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
