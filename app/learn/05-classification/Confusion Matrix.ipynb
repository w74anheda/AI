{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a44c82d",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Confusion Matrix</font>\n",
    "\n",
    "<p>A confusion matrix is a table that is often used to <strong>describe the performance of a classification model</strong> (or \"classifier\") on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand.</p>\n",
    "\n",
    "<img src=\"../../img/confusion_matrix_simple2.png\">\n",
    "\n",
    "<p>What can we learn from this matrix?</p>\n",
    "<ul>\n",
    "<li>There are two possible predicted classes: \"yes\" and \"no\". If we were predicting the presence of a disease, for example, \"yes\" would mean they have the disease, and \"no\" would mean they don't have the disease.</li>\n",
    "<li>The classifier made a total of 165 predictions (e.g., 165 patients were being tested for the presence of that disease).</li>\n",
    "<li>Out of those 165 cases, the classifier predicted \"yes\" 110 times, and \"no\" 55 times.</li>\n",
    "<li>In reality, 105 patients in the sample have the disease, and 60 patients do not.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Let's now define the most basic terms, which are whole numbers (not rates):</p>\n",
    "<ul>\n",
    "<li><strong>true positives (TP):</strong> These are cases in which we predicted yes (they have the disease), and they do have the disease.</li>\n",
    "<li><strong>true negatives (TN):</strong> We predicted no, and they don't have the disease.</li>\n",
    "<li><strong>false positives (FP):</strong> We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")</li>\n",
    "<li><strong>false negatives (FN):</strong> We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p>Let's now define the most basic terms, which are whole numbers (not rates):</p>\n",
    "<img src=\"../../img/confusion_matrix2.png\">\n",
    "\n",
    "<ul>\n",
    "<li><strong>Accuracy:</strong> Overall, how often is the classifier correct?\n",
    "<ul>\n",
    "<li>(TP+TN)/total = (100+50)/165 = 0.91</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>Misclassification Rate:</strong> Overall, how often is it wrong?\n",
    "<ul>\n",
    "<li>(FP+FN)/total = (10+5)/165 = 0.09</li>\n",
    "<li>equivalent to 1 minus Accuracy</li>\n",
    "<li>also known as \"Error Rate\"</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>True Positive Rate:</strong> When it's actually yes, how often does it predict yes?\n",
    "<ul>\n",
    "<li>TP/actual yes = 100/105 = 0.95</li>\n",
    "<li>also known as \"Sensitivity\" or \"Recall\"</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>False Positive Rate:</strong> When it's actually no, how often does it predict yes?\n",
    "<ul>\n",
    "<li>FP/actual no = 10/60 = 0.17</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>True Negative Rate:</strong> When it's actually no, how often does it predict no?\n",
    "<ul>\n",
    "<li>TN/actual no = 50/60 = 0.83</li>\n",
    "<li>equivalent to 1 minus False Positive Rate</li>\n",
    "<li>also known as \"Specificity\"</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>Precision:</strong> When it predicts yes, how often is it correct?\n",
    "<ul>\n",
    "<li>TP/predicted yes = 100/110 = 0.91</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>Prevalence:</strong> How often does the yes condition actually occur in our sample?\n",
    "<ul>\n",
    "<li>actual yes/total = 105/165 = 0.64</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "<p>A couple other terms are also worth mentioning:</p>\n",
    "\n",
    "<ul>\n",
    "<li><strong>Null Error Rate:</strong> This is how often you would be wrong if you always predicted the majority class. (In our example, the null error rate would be 60/165=0.36 because if you always predicted yes, you would only be wrong for the 60 \"no\" cases.) This can be a useful baseline metric to compare your classifier against. However, the best classifier for a particular application will sometimes have a higher error rate than the null error rate, as demonstrated by the <a href=\"http://en.wikipedia.org/wiki/Accuracy_paradox\">Accuracy Paradox</a>.</li>\n",
    "<li><strong>Cohen's Kappa:</strong> This is essentially a measure of how well the classifier performed as compared to how well it would have performed simply by chance. In other words, a model will have a high Kappa score if there is a big difference between the accuracy and the null error rate. (<a href=\"http://en.wikipedia.org/wiki/Cohen's_kappa\">More details about Cohen's Kappa.</a>)</li>\n",
    "<li><strong>F Score:</strong> This is a weighted average of the true positive rate (recall) and precision. (<a href=\"http://en.wikipedia.org/wiki/F1_score\">More details about the F Score.</a>)</li>\n",
    "<li><strong>ROC Curve:</strong> This is a commonly used graph that summarizes the performance of a classifier over all possible thresholds. It is generated by plotting the True Positive Rate (y-axis) against the False Positive Rate (x-axis) as you vary the threshold for assigning observations to a given class. (<a href=\"https://www.dataschool.io/roc-curves-and-auc-explained/\">More details about ROC Curves.</a>)</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<img src=\"../../img/1_BT3awaBdZHsit5s41LPb9A.png\">\n",
    "<img src=\"../../img/1_QRIZDkk_FffXKs_07ZlhZw.png\">\n",
    "<img src=\"../../img/1_98FaAKfPWo-EBTbjsxm4GA.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a79093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as PLT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as PLT, cm as CMAP\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01928090",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6e7b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_labels = list(zip(DT.images,DT.target))\n",
    "for index,(image,label) in enumerate(img_labels[100:104]):\n",
    "    PLT.subplot(1,4,index+1)\n",
    "    PLT.imshow(image,cmap=CMAP.gray_r)\n",
    "    PLT.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4acbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DT.images.reshape(len(DT.images),-1)\n",
    "Y = DT.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5842181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da530060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.fit(X[:1000],Y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7842faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = svm_classifier.predict(X[1000:])\n",
    "expected = Y[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e7081b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        79\n",
      "           1       0.97      0.96      0.97        80\n",
      "           2       1.00      0.97      0.99        77\n",
      "           3       0.97      0.85      0.91        79\n",
      "           4       0.99      0.95      0.97        83\n",
      "           5       0.92      0.99      0.95        82\n",
      "           6       0.99      0.99      0.99        80\n",
      "           7       0.94      0.99      0.96        80\n",
      "           8       0.92      0.96      0.94        76\n",
      "           9       0.92      0.95      0.93        81\n",
      "\n",
      "    accuracy                           0.96       797\n",
      "   macro avg       0.96      0.96      0.96       797\n",
      "weighted avg       0.96      0.96      0.96       797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(expected,predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c44b495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0, 77,  0,  0,  0,  0,  0,  0,  1,  2],\n",
       "       [ 1,  0, 75,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 67,  0,  3,  0,  4,  5,  0],\n",
       "       [ 0,  0,  0,  0, 79,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0, 81,  1,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0, 79,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0, 79,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  1,  0,  0, 73,  1],\n",
       "       [ 0,  0,  0,  1,  0,  2,  0,  1,  0, 77]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(expected,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fdba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
